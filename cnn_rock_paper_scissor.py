# -*- coding: utf-8 -*-
"""CNN Rock Paper Scissor.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-9EfU_14Mwd0HXuTEDqSYzh3cjiIIMeI
"""

import tensorflow as tf

!wget --no-check-certificate \
  https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip \
  -O /tmp/rockpaperscissors.zip #Download dataset

import zipfile,os
from shutil import copyfile

local_zip = '/tmp/rockpaperscissors.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/tmp')
zip_ref.close()

def split_data(input_dir, output_dir, validation_split=0.4):
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    for subdir, dirs, files in os.walk(input_dir):
        for file in files:
            file_path = os.path.join(subdir, file)
            if os.path.isfile(file_path):
                class_name = os.path.basename(subdir)

                train_dir = os.path.join(output_dir, 'train', class_name)
                validation_dir = os.path.join(output_dir, 'validation', class_name)

                for directory in [train_dir, validation_dir]:
                    if not os.path.exists(directory):
                        os.makedirs(directory)

                if hash(file) % 100 < validation_split * 100:
                    copyfile(file_path, os.path.join(validation_dir, file))
                else:
                    copyfile(file_path, os.path.join(train_dir, file))

input_dir = '/tmp/rockpaperscissors/rps-cv-images'
output_dir = '/tmp/rockpaperscissors/complete'

split_data(input_dir, output_dir, validation_split=0.4)

os.listdir('/tmp/rockpaperscissors/complete') #Pembagian berdasarkan folder dataset

from tensorflow.keras.preprocessing.image import ImageDataGenerator
train_datagen = ImageDataGenerator(
                    rescale=1./255,
                    rotation_range=20,
                    horizontal_flip=True,
                    shear_range = 0.2,
                    fill_mode = 'nearest')

test_datagen = ImageDataGenerator(
                    rescale=1./255)

train_generator = train_datagen.flow_from_directory(
        os.path.join(output_dir, 'train'),
        target_size=(150, 150),
        classes=['paper', 'rock', 'scissors'], #Pembagian menjadi 3 class
        class_mode='categorical',
        shuffle=True,
        batch_size=32)

validation_generator = test_datagen.flow_from_directory(
        os.path.join(output_dir, 'validation'),
        target_size=(150, 150),
        classes=['paper', 'rock', 'scissors'], #Pembagian menjadi 3 class
        class_mode='categorical',
        batch_size=32)

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(512, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
])

model.summary()

model.compile(loss='categorical_crossentropy',
              optimizer=tf.optimizers.Adam(),
              metrics=['accuracy'])

history = model.fit(
      train_generator,
      epochs=25,
      validation_data=validation_generator,
      validation_steps=1)

accuracy = model.evaluate(train_generator)[1]

print(f'Akurasi pada data validasi: {accuracy * 100:.2f}%')

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
from google.colab import files
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
# %matplotlib inline

uploaded = files.upload()

for fn in uploaded.keys():

  # predicting images
  path = fn
  img = image.load_img(path, target_size=(150,150))

  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  images = np.vstack([x])

  predictions = model.predict(images, batch_size=10)
  predicted_class_index = np.argmax(predictions[0])

  classes = ['scissors', 'rock', 'paper']
  predicted_class = classes[predicted_class_index]
  print(f'File: {fn}, Prediksi: {predicted_class}')

classes

print(train_generator.class_indices)